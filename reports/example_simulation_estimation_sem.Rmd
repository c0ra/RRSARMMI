---
title: "Ridge regularization for spatial auto-regressive models with multicollinearity issues"
subtitle: "Simulation of SEM model and estimation with RRSEM method"
author: "Chavez-Chong, C., Hardouin, C., Fermin, A.K."
output:
  html_document:
    df_print: paged
    code_folding: show
    toc: true
---

```{r, include=FALSE}
## Global options for code chunks
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE,
  fig.width=5,fig.height=5,fig.align="center"
)
```

### Preamble

In this preamble, we load the necessary libraries, and clean the workspace.

```{r loading_library, message=FALSE, echo = TRUE, collapse=TRUE}
rm(list=ls())

####  PACKAGES AND FUNCTIONS

# Random Gaussian fields
#install.packages("RandomFields")
library(RandomFields)

# Distance matrices
#install.packages("spdep")
library(spdep)
#install.packages("lctools")
library(lctools)

# Data management
#install.packages("dplyr")
library(dplyr)
#install.packages("calibrate")
library(calibrate)

```

## Introduction

In our paper entitled "Ridge regularization for spatial autoregressive models with multicollinearity issues", we introduce a novel approach for conducting Ridge regression for spatial autoregressive models.
In this document we provide the R code used for the simulations in the case of the SEM model defined in equation (2) of the article.
As a reference, here is the **RRSEM estimation algorithm** that we propose:


1. Initialization. Consider the ordinary linear regression model $\mathbf{Y}=\mathbf{X}\pmb{\beta}+\pmb{\varepsilon}$ and estimate $\pmb{\beta}$ by $\hat{\pmb{\beta}}_{R}$
2.  Consider   $\mathbf{ Y}_\lambda =\mathbf{X}_\lambda\hat{\pmb{\beta}}_R+\pmb{\varepsilon}$ and $\mathbf{e}_\lambda=\mathbf{y}_\lambda-\mathbf{X}_\lambda\hat{\pmb{\beta}}_R$  and estimate  $\lambda$ by using the concentrated  maximum likelihood (ML).   
3.  Consider the filtered  $\mathbf{Y}_{\hat\lambda} = (\mathbf{I }- \hat\lambda W)\mathbf{Y}$, the filtered matrix  $\mathbf{X}_{\hat\lambda} = (\mathbf{I }- \hat\lambda W)\mathbf{X}$,  and 
compute $$ \hat{\pmb{\beta}}_{R}^{SEM}=(\mathbf{X}^T_{\hat\lambda}\mathbf{X}_{\hat\lambda}+\gamma\mathbf{I}_p)^{-1}\mathbf{X}^T_{\hat\lambda}\mathbf{Y}_{\hat\lambda}$$  for $\gamma >0$. 
4. Consider $\mathbf{ Y}_\lambda =\mathbf{X}_\lambda\hat{\pmb{\beta}}_R^{SEM}+\pmb{\varepsilon}$ and $\mathbf{e}_\lambda=\mathbf{y}_\lambda-\mathbf{X}_\lambda\hat{\pmb{\beta}}_R^{SEM}$  and estimate new $\lambda$ by using the concentrated  ML.   
5.  Repeat step 3 to obtain the final  $ \hat{\pmb{\beta}}_{R}^{SEM}$ 

The objective of this document is to provide the scheme of our simulation study. The document is organized as follows, first we will generate the data and second we will perform the necessary computations.

## Data Simulation

First, we create the grid. We considered a 30x30 grid contained in the square $[0,1]\times[0,1]$ for our simulation.
```{r createGrid, echo = TRUE, collapse=TRUE}
  gridsize = c(30L, 30L)
  n= gridsize[1]
  m= gridsize[2]
  Xvec <- seq(0, 1, len = gridsize[1])
  Yvec <- seq(0, 1, len = gridsize[2])
  grd <- expand.grid(Y = Yvec, X = Xvec)
```

Then, we consider a contiguity matrix with rook neighbours `cont_mat`. The spatial weights matrix  `W` is constructed by row-standardizing the contiguity matrix.
```{r computeW, echo = TRUE, collapse=TRUE}
  cont_mat <- lat2w(ncol=n, nrow=m, rook = TRUE)
  W <- cont_mat$w/rowSums(cont_mat$w)
```

We generate the first covariate `x.1` as a Gaussian random field with an  exponential covariance function `expCov` with variance equal to 1 and scale set to 0.5.

```{r computeX1, echo = TRUE, collapse=TRUE}
  expCov <- RMexp(var = 0.1, scale = 0.1)
  x.1 <- as.vector(t(RFsimulate(expCov, x = Xvec, y = Yvec, spConform = FALSE)))
```

We generate the second covariate `x.2` as a Gaussian random field with a Gaussian covariance function `gausssCov` with variance equal to 1 and scale set to 0.4. Finally, we scale the variable.

```{r computeX2, echo = TRUE, collapse=TRUE}
  gaussCov <- RMgauss(var = 0.1, scale = 0.1) #0.4 was a bit much
  x.2 <- as.vector(t(RFsimulate(gaussCov, x = Xvec, y = Yvec, spConform = FALSE)))
```


We generate the remaining 6 variables as functions of the initial covariates and combinations of themselves. 

```{r computeX4toX8, echo = TRUE, collapse=TRUE}

  x.3 = exp(x.1) - abs(x.2)
  
  x.4 = abs(x.2) +(x.1/2+x.2/2-4)^2
  
  x.5 = x.1  + x.1*x.2
  
  x.6 = log(x.4) - x.1/12 + x.1^2
  
  x.7 = x.1 + 2*x.2 + sqrt(x.4)
  
  x.8 = x.5  +x.2/2 + x.2^2
```

Next, we create a dataframe with the variables `covariates`, obtain the model matrix `X` and we standardize all the variables in the matrix.

```{r createModelMatrix, echo = TRUE, collapse=TRUE}
  covariates = data.frame( mget(paste0("x.", c(1:8))))
  X = as.matrix(covariates)
  X <- apply(X, 2, function(x){(x-mean(x))/sd(x)})
```

We compute the correlation matrix to show the presence of multicollinearity in the model matrix

```{r corrPlot, echo = TRUE, collapse=TRUE}
  corrplot::corrplot(cor(X), method="circle", type="upper")
```


We consider in the paper the structure of the SEM model, with 5 different values of the spatial autoregressive coefficient reflecting weak to strong dependence,   $\rho\ \in (0.1, 0.3, 0.5, 0.7, 0.9)$. Here we present the simulation for $\rho = 0.3$. First, we will compute $(\mathbf{I} - \rho W)^{-1}$.

```{r computeDepFactor, echo = TRUE, collapse=TRUE}
  
  rho=0.3
  factor_0.3 <- solve(diag(1, n*m) - rho*W)  

```

 We proceed to generate simulations of the dependent variable $\mathbf{y}$ for each value of the dependent  determined by the equation:
$$
\mathbf{y}=\mathbf{X}\pmb{\beta} + (I_n-\rho W)^{-1}\pmb{\varepsilon},
$$
In this report we will work with 1 simulation of the dependent variable to illustrate the procedure, in our paper we give the results for 500 simulations.

 We store the number of covariates in `p`.

```{r createDataframe, echo = TRUE, collapse=TRUE}

  p = ncol(X)

```

We compute the dependent variable. The error term is the product of a sampled standard normal distribution `epsilon` and $(\mathbf{I} - \rho W)^{-1}$. The vector of $\beta$ coefficients is set to a vector of ones `ones(p,1)`. Then, we center the dependent variable. Finally, we store the simulated data in a dataframe `sim.data`.

```{r computeDepVariable, echo = TRUE, collapse=TRUE}

  epsilon <- rnorm(n*m, mean=0, sd=1) 
  
  y_lag_0.3 <- factor_0.3%*%X%*%ones(p,1) + factor_0.3%*%epsilon
  sd_y_lag_0.3 <- sd(y_lag_0.3)
  y_lag_0.3 <- (y_lag_0.3-mean(y_lag_0.3))
  

 
  sim.data  <- data.frame(mget(paste0("x.", 1:p)), 
                               y_lag_0.3,
                                sd_y_lag_0.3)


```

## Estimation
In our paper we conducted a comparison of our estimation procedure with several other approaches: Ordinary least squares regression (OLS), ordinary Ridge regression (RR), ordinary SEM (SEM) without regularization and Spatially Filtered Ridge Regression (SFRR).

To assess the performance of these estimation procedures, we computed the Mean Squared Error (MSE) of the coefficient estimates as evaluation metric.  Here we will show how we estimate the coefficients using the different procedures.

First, we load the script with the estimation functions.

```{r loadFunctions, echo = TRUE, collapse=TRUE, message = FALSE}
  
  setwd("C:/Users/crist/OneDrive/Documents/sim_RRSAR")
  source("scripts/functions_numerical_experiments.R")

```

Now we are starting the estimation procedure. Note that we are working without an intercept.

```{r model, echo = TRUE, collapse=TRUE}

  model = y_lag_0.3~x.1+x.2+x.3+x.4+x.5+x.6+x.7+x.8-1 

```

*OLS estimation* To estimate the regression coefficients we use the `lm` function. Then, we store the coefficients in `coef_ols`.

```{r ols, echo = TRUE, collapse=TRUE}
   
  ols_lag <- lm(model, data=sim.data)
  coef_ols <-  ols_lag$coefficients

```

*Ordinary SEM estimation* We transform the spatial weights matrix `W` into a weights list object `listw`. To estimate the SEM coefficients we use the `lagsarlm` function (package `spatialreg`). Then, we store the regression coefficients in `coef_sar` and the estimated spatial dependence parameter in `rho_sar`.

```{r sar, echo = TRUE, collapse=TRUE, message=FALSE}

  listw <- mat2listw(W)
  sar_lag <- spatialreg::lagsarlm(model, listw= listw, data = sim.data)
  coef_sar <- sar_lag$coefficients
  rho_sar <- sar_lag$rho

```

*Ridge estimation (without spatial filter)*To estimate the ridge regression coefficients we use the `ridgeRegression` function from the script loaded at the begining of this section. Then, we store the regression coefficients in `coef_RR`.

```{r RidgeRegression, echo = TRUE, collapse=TRUE}

  RR_lag <- ridgeRegression(y_lag_0.3, X)
  coef_RR<-  RR_lag$beta

```

*SFRR estimation* To estimate the SFRR coefficients we first apply the filter to the dependent variable, using the value of  $\rho$ estimated with the SEM model `rho_sar`. The we use the `ridgeRegression` function from the script loaded at the begining of this section with the filtered dependent variable `y_filtered`. Then, we store the regression coefficients in `coef_SFRR`.

```{r SFRR, echo = TRUE, collapse=TRUE}

    y_filtered <- (diag(length(y_lag_0.3)) - rho_sar *W) %*% y_lag_0.3
    
    SFRR_lag <- ridgeRegression(y_filtered, X)
    coef_SFRR <-   SFRR_lag$beta

```




*RRSEM estimation* To estimate the RRSEM coefficients we use the `rrsem` function from the script loaded at the begining of this section.
We specify:

* the `data` object, i.e. a dataframe containing variables used in the model.
* the `grid` object, i.e. a dataframe containing the grid points.
* the `model` object containing the model used.
* the `buffer` object, i.e. the size of the buffer considered in Spatial Leave One Out

Then, we store the regression coefficients in `coef_RRSEM` and the estimated spatial dependence parameter in `rho_RRSEM`.


```{r RRSEM, echo = TRUE, collapse=TRUE, message = FALSE, message=FALSE,  eval=FALSE}

    RRSEM_lag <- rrsem(data=sim.data, grid=grd, model=model, buffer=1)
    rho_RRSEM <- RRSEM_lag$rho
    coef_RRSEM <-   RRSEM_lag$Coefficients

```




